{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f6de001",
   "metadata": {},
   "source": [
    "# Predicción de Precio de Coches - Análisis Exploratorio y Selección de Variables\n",
    "\n",
    "Este notebook documenta el análisis exploratorio realizado para el proyecto de predicción de precios de coches. Incluye la selección de variables mediante RFE y la evaluación de multicolinealidad con VIF. Sirve como respaldo técnico del pipeline implementado en `train.py`, dentro del marco del proyecto MLOps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7360c2c5",
   "metadata": {},
   "source": [
    "## 1. Planteamiento del Problema\n",
    "Geely Auto, una empresa automovilística china, desea introducirse en el mercado estadounidense. Para ello, necesita entender cómo las características de los vehículos influyen en su precio. Este análisis pretende modelar dicha relación para apoyar decisiones estratégicas y de diseño."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96d2aca",
   "metadata": {},
   "source": [
    "## 2. Objetivo del Negocio\n",
    "El objetivo es construir un modelo interpretable de regresión lineal que explique el precio de un automóvil en función de sus características técnicas y categóricas. Este notebook se enfoca en la exploración de los datos y la selección justificativa de variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd248f3",
   "metadata": {},
   "source": [
    "## 3. Importación de Librerías\n",
    "Se importan librerías necesarias para el análisis exploratorio, la regresión lineal, y las métricas estadísticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dcdd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66201391",
   "metadata": {},
   "source": [
    "## 4. Carga de Datos\n",
    "Cargamos el dataset original y realizamos una primera limpieza básica de columnas irrelevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d86c09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/CarPrice_Assignment.csv\")\n",
    "df.drop(columns=['car_ID'], inplace=True)\n",
    "df['CarBrand'] = df['CarName'].apply(lambda x: x.split(' ')[0].lower())\n",
    "df.drop(columns=['CarName'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f3f097",
   "metadata": {},
   "source": [
    "## 5. Corrección de Valores Erróneos\n",
    "Algunas marcas están mal escritas. Esta limpieza es clave para evitar codificaciones erróneas al aplicar One-Hot Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f466373",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CarBrand'] = df['CarBrand'].replace({\n",
    "    'maxda': 'mazda',\n",
    "    'porcshce': 'porsche',\n",
    "    'toyouta': 'toyota',\n",
    "    'vokswagen': 'volkswagen',\n",
    "    'vw': 'volkswagen',\n",
    "    'Nissan': 'nissan'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f37473",
   "metadata": {},
   "source": [
    "## 6. Transformación de Variables Categóricas\n",
    "Aplicamos One-Hot Encoding a las variables categóricas para poder usarlas en regresión lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf957d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b02d30f",
   "metadata": {},
   "source": [
    "## 7. Separación de Variables Independientes y Dependiente\n",
    "La variable objetivo (`price`) se separa de las variables predictoras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69210fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_encoded.drop(columns=['price'])\n",
    "y = df_encoded['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f982fb1",
   "metadata": {},
   "source": [
    "## 8. Selección de Variables con RFE\n",
    "Aplicamos Recursive Feature Elimination con regresión lineal como modelo base para seleccionar las 15 variables más relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e62fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "rfe = RFE(model, n_features_to_select=15)\n",
    "rfe.fit(X, y)\n",
    "\n",
    "selected_columns = X.columns[rfe.support_]\n",
    "X_rfe = X[selected_columns]\n",
    "selected_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae1f94f",
   "metadata": {},
   "source": [
    "## 9. Evaluación de Multicolinealidad con VIF\n",
    "Para asegurar que no haya redundancia excesiva entre las variables seleccionadas, se calcula el Factor de Inflación de la Varianza (VIF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0da1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = selected_columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_rfe.values, i) for i in range(X_rfe.shape[1])]\n",
    "vif_data.sort_values(by=\"VIF\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493bb672",
   "metadata": {},
   "source": [
    "## 10. Conclusiones\n",
    "Las variables seleccionadas por RFE y depuradas mediante VIF son las que se han utilizado finalmente en el script `train.py`. Este proceso garantiza un modelo lineal simple, interpretable y con bajo riesgo de multicolinealidad."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
